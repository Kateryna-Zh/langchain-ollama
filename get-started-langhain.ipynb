{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "065a2c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2\", temperature=0.0)\n",
    "creative_llm = ChatOllama(model=\"llama3.2\", temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c6952fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "article = \"\"\"\n",
    "\\\n",
    "We believe AI's short—to mid-term future belongs to agents and that the long-term future of *AGI* may evolve from agentic systems. Our definition of agents covers any neuro-symbolic system in which we merge neural AI (such as an LLM) with semi-traditional software.\n",
    "\n",
    "With agents, we allow LLMs to integrate with code — allowing AI to search the web, perform math, and essentially integrate into anything we can build with code. It should be clear the scope of use cases is phenomenal where AI can integrate with the broader world of software.\n",
    "\n",
    "In this introduction to AI agents, we will cover the essential concepts that make them what they are and why that will make them the core of real-world AI in the years to come.\n",
    "\n",
    "---\n",
    "\n",
    "## Neuro-Symbolic Systems\n",
    "\n",
    "Neuro-symbolic systems consist of both neural and symbolic computation, where:\n",
    "\n",
    "- Neural refers to LLMs, embedding models, or other neural network-based models.\n",
    "- Symbolic refers to logic containing symbolic logic, such as code.\n",
    "\n",
    "Both neural and symbolic AI originate from the early philosophical approaches to AI: connectionism (now neural) and symbolism. Symbolic AI is the more traditional AI. Diehard symbolists believed they could achieve true AGI via written rules, ontologies, and other logical functions.\n",
    "\n",
    "The other camp were the connectionists. Connectionism emerged in 1943 with a theoretical neural circuit but truly kicked off with Rosenblatt's perceptron paper in 1958 [1][2]. Both of these approaches to AI are fascinating but deserve more time than we can give them here, so we will leave further exploration of these concepts for a future chapter.\n",
    "\n",
    "Most important to us is understanding where symbolic logic outperforms neural-based compute and vice-versa.\n",
    "\n",
    "| Neural | Symbolic |\n",
    "| --- | --- |\n",
    "| Flexible, learned logic that can cover a huge range of potential scenarios. | Mostly hand-written rules which can be very granular and fine-tuned but hard to scale. |\n",
    "| Hard to interpret why a neural system does what it does. Very difficult or even impossible to predict behavior. | Rules are written and can be understood. When unsure why a particular ouput was produced we can look at the rules / logic to understand. |\n",
    "| Requires huge amount of data and compute to train state-of-the-art neural models, making it hard to add new abilities or update with new information. | Code is relatively cheap to write, it can be updated with new features easily, and latest information can often be added often instantaneously. |\n",
    "| When trained on broad datasets can often lack performance when exposed to unique scenarios that are not well represented in the training data. | Easily customized to unique scenarios. |\n",
    "| Struggles with complex computations such as mathematical operations. | Perform complex computations very quickly and accurately. |\n",
    "\n",
    "Pure neural architectures struggle with many seemingly simple tasks. For example, an LLM *cannot* provide an accurate answer if we ask it for today's date.\n",
    "\n",
    "Retrieval Augmented Generation (RAG) is commonly used to provide LLMs with up-to-date knowledge on a particular subject or access to proprietary knowledge.\n",
    "\n",
    "### Giving LLMs Superpowers\n",
    "\n",
    "By 2020, it was becoming clear that neural AI systems could not perform tasks symbolic systems typically excelled in, such as arithmetic, accessing structured DB data, or making API calls. These tasks require discrete input parameters that allow us to process them reliably according to strict written logic.\n",
    "\n",
    "In 2022, researchers at AI21 developed Jurassic-X, an LLM-based \"neuro-symbolic architecture.\" Neuro-symbolic refers to merging the \"neural computation\" of large language models (LLMs) with more traditional (i.e. symbolic) computation of code.\n",
    "\n",
    "Jurassic-X used the Modular Reasoning, Knowledge, and Language (MRKL) system [3]. The researchers developed MRKL to solve the limitations of LLMs, namely:\n",
    "\n",
    "- Lack of up-to-date knowledge, whether that is the latest in AI or something as simple as today's date.\n",
    "- Lack of proprietary knowledge, such as internal company docs or your calendar bookings.\n",
    "- Lack of reasoning, i.e. the inability to perform operations that traditional software is good at, like running complex mathematical operations.\n",
    "- Lack of ability to generalize. Back in 2022, most LLMs had to be fine-tuned to perform well in a specific domain. This problem is still present today but far less prominent as the SotA models generalize much better and, in the case of MRKL, are able to use tools relatively well (although we could certainly take the MRKL solution to improve tool use performance even today).\n",
    "\n",
    "MRKL represents one of the earliest forms of what we would now call an agent; it is an LLM (neural computation) paired with executable code (symbolic computation).\n",
    "\n",
    "## ReAct and Tools\n",
    "\n",
    "There is a misconception in the broader industry that an AI agent is an LLM contained within some looping logic that can generate inputs for and execute code functions. This definition of agents originates from the huge popularity of the ReAct agent framework and the adoption of a similar structure with function/tool calling by LLM providers such as OpenAI, Anthropic, and Ollama.\n",
    "\n",
    "![ReAct agent flow with the Reasoning-Action loop [4]. When the action chosen specifies to use a normal tool, the tool is used and the observation returned for another iteration through the Reasoning-Action loop. To return a final answer to the user the LLM must choose action \"answer\" and provide the natural language response, finishing the loop.](/images/posts/ai-agents/ai-agents-00.png)\n",
    "\n",
    "<small>ReAct agent flow with the Reasoning-Action loop [4]. When the action chosen specifies to use a normal tool, the tool is used and the observation returned for another iteration through the Reasoning-Action loop. To return a final answer to the user the LLM must choose action \"answer\" and provide the natural language response, finishing the loop.</small>\n",
    "\n",
    "Our \"neuro-symbolic\" definition is much broader but certainly does include ReAct agents and LLMs paired with tools. This agent type is the most common for now, so it's worth understanding the basic concept behind it.\n",
    "\n",
    "The **Re**ason **Act**ion (ReAct) method encourages LLMs to generate iterative *reasoning* and *action* steps. During *reasoning,* the LLM describes what steps are to be taken to answer the user's query. Then, the LLM generates an *action,* which we parse into an input to some executable code, which we typically describe as a tool/function call.\n",
    "\n",
    "![ReAct method. Each iteration includes a Reasoning step followed by an Action (tool call) step. The Observation is the output from the previous tool call. During the final iteration the agent calls the answer tool, meaning we generate the final answer for the user.](/images/posts/ai-agents/ai-agents-01.png)\n",
    "\n",
    "<small>ReAct method. Each iteration includes a Reasoning step followed by an Action (tool call) step. The Observation is the output from the previous tool call. During the final iteration the agent calls the answer tool, meaning we generate the final answer for the user.</small>\n",
    "\n",
    "Following the reason and action steps, our action tool call returns an observation. The logic returns the observation to the LLM, which is then used to generate subsequent reasoning and action steps.\n",
    "\n",
    "The ReAct loop continues until the LLM has enough information to answer the original input. Once the LLM reaches this state, it calls a special *answer* action with the generated answer for the user.\n",
    "\n",
    "## Not only LLMs and Tool Calls\n",
    "\n",
    "LLMs paired with tool calling are powerful but far from the only approach to building agents. Using the definition of neuro-symbolic, we cover architectures such as:\n",
    "\n",
    "- Multi-agent workflows that involve multiple LLM-tool (or other agent structure) combinations.\n",
    "- More deterministic workflows where we may have set neural model-tool paths that may fork or merge as the use case requires.\n",
    "- Embedding models that can detect user intents and decide tool-use or LLM selection-based selection in vector space.\n",
    "\n",
    "These are just a few high-level examples of alternative agent structures. Far from being designed for niche use cases, we find these alternative options to frequently perform better than the more common ReAct or Tool agents. We will cover all of these examples and more in future chapters.\n",
    "\n",
    "---\n",
    "\n",
    "Agents are fundamental to the future of AI, but that doesn't mean we should expect that future to come from agents in their most popular form today. ReAct and Tool agents are great and handle many simple use cases well, but the scope of agents is much broader, and we believe thinking beyond ReAct and Tools is key to building future AI.\n",
    "\n",
    "---\n",
    "\n",
    "You can sign up for the [Aurelio AI newsletter](https://b0fcw9ec53w.typeform.com/to/w2BDHVK7) to stay updated on future releases in our comprehensive course on agents.\n",
    "\n",
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "[1] The curious case of Connectionism (2019) [https://www.degruyter.com/document/doi/10.1515/opphil-2019-0018/html](https://www.degruyter.com/document/doi/10.1515/opphil-2019-0018/html)\n",
    "\n",
    "[2] F. Rosenblatt, [The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain](https://www.ling.upenn.edu/courses/cogs501/Rosenblatt1958.pdf) (1958), Psychological Review\n",
    "\n",
    "[3] E. Karpas et al. [MRKL Systems: A Modular, Neuro-Symbolic Architecture That Combines Large Language Models, External Knowledge Sources and Discrete Reasoning](https://arxiv.org/abs/2205.00445) (2022), AI21 Labs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "109ca977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate   \n",
    "\n",
    "system_prompt = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are an expert that helps generate article titles.\"\n",
    ")\n",
    "\n",
    "user_prompt = HumanMessagePromptTemplate.from_template(\n",
    "    \"\"\"You are tasked with creating a name for a article.\n",
    "The article is here for you to examine {article}\n",
    "\n",
    "Generate 10 unique names for the article. \n",
    "The names should be based of the context of the article. \n",
    "Be creative, but make sure the names are clear, catchy, \n",
    "and relevant to the theme of the context.\n",
    "\n",
    "Compare all the names, and decide which name is best based on\n",
    "How catchy the name is, How creative the name is, and how relevant the name is.\n",
    "\n",
    "only output the best name as:\n",
    "Article Name: ...\"\"\", \n",
    "    input_variables=[\"article\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a261e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessage(content='You are tasked with creating a name for a article.\\nThe article is here for you to examine TEST ARTICLE\\n\\nGenerate 10 unique names for the article. \\nThe names should be based of the context of the article. \\nBe creative, but make sure the names are clear, catchy, \\nand relevant to the theme of the context.\\n\\nCompare all the names, and decide which name is best based on\\nHow catchy the name is, How creative the name is, and how relevant the name is.\\n\\nonly output the best name as:\\nArticle Name: ...', additional_kwargs={}, response_metadata={})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt.format(article=\"TEST ARTICLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24e4a391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def wrap(prompt, llm, parcer, output_key):\n",
    "    inner_chain = prompt | llm | parcer\n",
    "    return RunnableLambda(\n",
    "        lambda state: {\n",
    "            **state,\n",
    "            output_key: inner_chain.invoke(state)\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56b5b139",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_prompt, user_prompt]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21b098ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are an expert that helps generate article titles.\n",
      "Human: You are tasked with creating a name for a article.\n",
      "The article is here for you to examine TEST ARTICLE\n",
      "\n",
      "Generate 10 unique names for the article. \n",
      "The names should be based of the context of the article. \n",
      "Be creative, but make sure the names are clear, catchy, \n",
      "and relevant to the theme of the context.\n",
      "\n",
      "Compare all the names, and decide which name is best based on\n",
      "How catchy the name is, How creative the name is, and how relevant the name is.\n",
      "\n",
      "only output the best name as:\n",
      "Article Name: ...\n"
     ]
    }
   ],
   "source": [
    "print(first_prompt.format(article=\"TEST ARTICLE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffb10dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c17dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_user_prompt = HumanMessagePromptTemplate.from_template(\"\"\"\n",
    "   You are tasked with creating a description for the article.\n",
    "    The article is here for you to examine {article}\n",
    "    Here is the name of the article {article_title}\n",
    "    Follow these steps carefully but dont put the steps in the final output:\n",
    "\n",
    "    Step 1:\n",
    "    Summarise the content of the article.\n",
    "    The description should be 2 sentences long, \n",
    "\n",
    "    Step 2:\n",
    "    format the output the summary generated as\n",
    "    Article Summary: ...\"\"\",\n",
    "    input_variables=[\"article\", \"article_title\"]\n",
    ") \n",
    "\n",
    "second_prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_prompt, second_user_prompt]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc43ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "third_user_prompt = HumanMessagePromptTemplate.from_template(\"\"\"\n",
    "    You are tasked with creating a new paragraph for the article.\n",
    "The article is here for you to examine {article}\n",
    "Follow these steps carefully but dont put the steps in the final output:\n",
    "\n",
    "Find 5 key areas the article does not talk about.\n",
    "Compare each key area and decide which is most related to the subject of the context.\n",
    "Generate a new paragraph of the most related key area in the same style as the context.\n",
    "\n",
    "only output the final paragraph formatted as:\n",
    "Article Paragraph: ...\n",
    "\"\"\")\n",
    "\n",
    "third_prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_prompt, third_user_prompt]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60dd29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourth_user_prompt = HumanMessagePromptTemplate.from_template(\"\"\"\n",
    "    You are tasked with adding a new paragraph for the article.\n",
    "    \n",
    "    The article is here for you to examine {article}\n",
    "    The new paragraph is also here for you to examine {article_para}\n",
    "\n",
    "    Find the line the article paragraph should come after and discuss why is should be placed there.\n",
    "\n",
    "    format this as\n",
    "    Article Paragraph Line: ...\n",
    "    \"\"\")\n",
    "\n",
    "fourth_prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_prompt, fourth_user_prompt]\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23818d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "image_prompt = PromptTemplate(\n",
    "    input_variables=[\"article\"],\n",
    "    template=\"Generate a prompt with less then 500 letters to create an image based on the following article: {article}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2fb767b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_one   = wrap(first_prompt,  creative_llm, parser, \"article_title\")\n",
    "chain_two   = wrap(second_prompt, creative_llm, parser, \"summary\")\n",
    "chain_three = wrap(third_prompt,  creative_llm, parser, \"article_para\")\n",
    "chain_four  = wrap(fourth_prompt, creative_llm, parser, \"new_suggestion\")\n",
    "chain_five  = wrap(image_prompt,  creative_llm, parser, \"image_prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c1ed503",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnableSequence\n",
    "\n",
    "start = RunnableLambda(lambda x: {\"article\": x[\"article\"]})\n",
    "full_chain = RunnableSequence(\n",
    "    start,\n",
    "    chain_one,\n",
    "    chain_two,\n",
    "    chain_three,\n",
    "    chain_four,\n",
    "    chain_five\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd637e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'article': '\\nWe believe AI\\'s short—to mid-term future belongs to agents and that the long-term future of *AGI* may evolve from agentic systems. Our definition of agents covers any neuro-symbolic system in which we merge neural AI (such as an LLM) with semi-traditional software.\\n\\nWith agents, we allow LLMs to integrate with code — allowing AI to search the web, perform math, and essentially integrate into anything we can build with code. It should be clear the scope of use cases is phenomenal where AI can integrate with the broader world of software.\\n\\nIn this introduction to AI agents, we will cover the essential concepts that make them what they are and why that will make them the core of real-world AI in the years to come.\\n\\n---\\n\\n## Neuro-Symbolic Systems\\n\\nNeuro-symbolic systems consist of both neural and symbolic computation, where:\\n\\n- Neural refers to LLMs, embedding models, or other neural network-based models.\\n- Symbolic refers to logic containing symbolic logic, such as code.\\n\\nBoth neural and symbolic AI originate from the early philosophical approaches to AI: connectionism (now neural) and symbolism. Symbolic AI is the more traditional AI. Diehard symbolists believed they could achieve true AGI via written rules, ontologies, and other logical functions.\\n\\nThe other camp were the connectionists. Connectionism emerged in 1943 with a theoretical neural circuit but truly kicked off with Rosenblatt\\'s perceptron paper in 1958 [1][2]. Both of these approaches to AI are fascinating but deserve more time than we can give them here, so we will leave further exploration of these concepts for a future chapter.\\n\\nMost important to us is understanding where symbolic logic outperforms neural-based compute and vice-versa.\\n\\n| Neural | Symbolic |\\n| --- | --- |\\n| Flexible, learned logic that can cover a huge range of potential scenarios. | Mostly hand-written rules which can be very granular and fine-tuned but hard to scale. |\\n| Hard to interpret why a neural system does what it does. Very difficult or even impossible to predict behavior. | Rules are written and can be understood. When unsure why a particular ouput was produced we can look at the rules / logic to understand. |\\n| Requires huge amount of data and compute to train state-of-the-art neural models, making it hard to add new abilities or update with new information. | Code is relatively cheap to write, it can be updated with new features easily, and latest information can often be added often instantaneously. |\\n| When trained on broad datasets can often lack performance when exposed to unique scenarios that are not well represented in the training data. | Easily customized to unique scenarios. |\\n| Struggles with complex computations such as mathematical operations. | Perform complex computations very quickly and accurately. |\\n\\nPure neural architectures struggle with many seemingly simple tasks. For example, an LLM *cannot* provide an accurate answer if we ask it for today\\'s date.\\n\\nRetrieval Augmented Generation (RAG) is commonly used to provide LLMs with up-to-date knowledge on a particular subject or access to proprietary knowledge.\\n\\n### Giving LLMs Superpowers\\n\\nBy 2020, it was becoming clear that neural AI systems could not perform tasks symbolic systems typically excelled in, such as arithmetic, accessing structured DB data, or making API calls. These tasks require discrete input parameters that allow us to process them reliably according to strict written logic.\\n\\nIn 2022, researchers at AI21 developed Jurassic-X, an LLM-based \"neuro-symbolic architecture.\" Neuro-symbolic refers to merging the \"neural computation\" of large language models (LLMs) with more traditional (i.e. symbolic) computation of code.\\n\\nJurassic-X used the Modular Reasoning, Knowledge, and Language (MRKL) system [3]. The researchers developed MRKL to solve the limitations of LLMs, namely:\\n\\n- Lack of up-to-date knowledge, whether that is the latest in AI or something as simple as today\\'s date.\\n- Lack of proprietary knowledge, such as internal company docs or your calendar bookings.\\n- Lack of reasoning, i.e. the inability to perform operations that traditional software is good at, like running complex mathematical operations.\\n- Lack of ability to generalize. Back in 2022, most LLMs had to be fine-tuned to perform well in a specific domain. This problem is still present today but far less prominent as the SotA models generalize much better and, in the case of MRKL, are able to use tools relatively well (although we could certainly take the MRKL solution to improve tool use performance even today).\\n\\nMRKL represents one of the earliest forms of what we would now call an agent; it is an LLM (neural computation) paired with executable code (symbolic computation).\\n\\n## ReAct and Tools\\n\\nThere is a misconception in the broader industry that an AI agent is an LLM contained within some looping logic that can generate inputs for and execute code functions. This definition of agents originates from the huge popularity of the ReAct agent framework and the adoption of a similar structure with function/tool calling by LLM providers such as OpenAI, Anthropic, and Ollama.\\n\\n![ReAct agent flow with the Reasoning-Action loop [4]. When the action chosen specifies to use a normal tool, the tool is used and the observation returned for another iteration through the Reasoning-Action loop. To return a final answer to the user the LLM must choose action \"answer\" and provide the natural language response, finishing the loop.](/images/posts/ai-agents/ai-agents-00.png)\\n\\n<small>ReAct agent flow with the Reasoning-Action loop [4]. When the action chosen specifies to use a normal tool, the tool is used and the observation returned for another iteration through the Reasoning-Action loop. To return a final answer to the user the LLM must choose action \"answer\" and provide the natural language response, finishing the loop.</small>\\n\\nOur \"neuro-symbolic\" definition is much broader but certainly does include ReAct agents and LLMs paired with tools. This agent type is the most common for now, so it\\'s worth understanding the basic concept behind it.\\n\\nThe **Re**ason **Act**ion (ReAct) method encourages LLMs to generate iterative *reasoning* and *action* steps. During *reasoning,* the LLM describes what steps are to be taken to answer the user\\'s query. Then, the LLM generates an *action,* which we parse into an input to some executable code, which we typically describe as a tool/function call.\\n\\n![ReAct method. Each iteration includes a Reasoning step followed by an Action (tool call) step. The Observation is the output from the previous tool call. During the final iteration the agent calls the answer tool, meaning we generate the final answer for the user.](/images/posts/ai-agents/ai-agents-01.png)\\n\\n<small>ReAct method. Each iteration includes a Reasoning step followed by an Action (tool call) step. The Observation is the output from the previous tool call. During the final iteration the agent calls the answer tool, meaning we generate the final answer for the user.</small>\\n\\nFollowing the reason and action steps, our action tool call returns an observation. The logic returns the observation to the LLM, which is then used to generate subsequent reasoning and action steps.\\n\\nThe ReAct loop continues until the LLM has enough information to answer the original input. Once the LLM reaches this state, it calls a special *answer* action with the generated answer for the user.\\n\\n## Not only LLMs and Tool Calls\\n\\nLLMs paired with tool calling are powerful but far from the only approach to building agents. Using the definition of neuro-symbolic, we cover architectures such as:\\n\\n- Multi-agent workflows that involve multiple LLM-tool (or other agent structure) combinations.\\n- More deterministic workflows where we may have set neural model-tool paths that may fork or merge as the use case requires.\\n- Embedding models that can detect user intents and decide tool-use or LLM selection-based selection in vector space.\\n\\nThese are just a few high-level examples of alternative agent structures. Far from being designed for niche use cases, we find these alternative options to frequently perform better than the more common ReAct or Tool agents. We will cover all of these examples and more in future chapters.\\n\\n---\\n\\nAgents are fundamental to the future of AI, but that doesn\\'t mean we should expect that future to come from agents in their most popular form today. ReAct and Tool agents are great and handle many simple use cases well, but the scope of agents is much broader, and we believe thinking beyond ReAct and Tools is key to building future AI.\\n\\n---\\n\\nYou can sign up for the [Aurelio AI newsletter](https://b0fcw9ec53w.typeform.com/to/w2BDHVK7) to stay updated on future releases in our comprehensive course on agents.\\n\\n---\\n\\n## References\\n\\n[1] The curious case of Connectionism (2019) [https://www.degruyter.com/document/doi/10.1515/opphil-2019-0018/html](https://www.degruyter.com/document/doi/10.1515/opphil-2019-0018/html)\\n\\n[2] F. Rosenblatt, [The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain](https://www.ling.upenn.edu/courses/cogs501/Rosenblatt1958.pdf) (1958), Psychological Review\\n\\n[3] E. Karpas et al. [MRKL Systems: A Modular, Neuro-Symbolic Architecture That Combines Large Language Models, External Knowledge Sources and Discrete Reasoning](https://arxiv.org/abs/2205.00445) (2022), AI21 Labs\\n', 'article_title': 'Here are 10 unique article title options:\\n\\n1. \"Agents of Change: Unlocking AI\\'s Potential\"\\n2. \"Beyond ReAct: The Future of Neuro-Symbolic Systems\"\\n3. \"Code Meets Brain: How Agents Will Revolutionize AI\"\\n4. \"The Agent Advantage: Where Symbolic Logic Meets Neural Networks\"\\n5. \"Integrating the Human Touch: The Rise of Agent-Based AI\"\\n6. \"Unleashing the Power of Hybrid Intelligence\"\\n7. \"Neuro-Symbolic Breakthroughs: A New Era for AI Agents\"\\n8. \"Agents Unleashed: Exploring the Frontiers of Neuro-Symbolic Systems\"\\n9. \"Code, Logic, and Reasoning: The Evolution of Agent-Based AI\"\\n10. \"Synergizing Symbolism and Neuroscience: The Future of Agent-Based Intelligence\"\\n\\nComparing these options, I recommend:\\n\\nArticle Name: \"Agents Unleashed: Exploring the Frontiers of Neuro-Symbolic Systems\"\\n\\nThis name stands out for its catchiness (\"Agents Unleashed\" is a memorable and exciting phrase) while also conveying the article\\'s focus on neuro-symbolic systems. The use of \"Frontiers\" suggests that the article will explore new and exciting territories, which aligns with the author\\'s vision for agents in AI.\\n\\nOverall, this name strikes a great balance between creativity (\"Agents Unleashed\") and relevance to the topic (\"Neuro-Symbolic Systems\"), making it an effective choice for an article about the future of agent-based AI.', 'summary': \"Based on your request, here is a well-formatted and concise article title and description.\\n\\n**Article Title:** Agents Unleashed: Exploring the Frontiers of Neuro-Symbolic Systems\\n\\n**Article Description:** \\nWe believe AI's short—to mid-term future belongs to agents and that the long-term future of *AGI* may evolve from agentic systems. Our definition of agents covers any neuro-symbolic system in which we merge neural AI (such as an LLM) with semi-traditional software.\\n\\n**Article Summary:**\\nWe believe AI's short—to mid-term future belongs to agents and that the long-term future of *AGI* may evolve from agentic systems. Our definition of agents covers any neuro-symbolic system in which we merge neural AI (such as an LLM) with semi-traditional software.\\n\\nLet me know if you'd like me to change anything!\", 'article_para': \"Article Paragraph: \\nAgents are fundamental to the future of AI, but that doesn't mean we should expect that future to come from agents in their most popular form today. While ReAct and Tool agents handle many simple use cases well, they are a narrow subset of what is possible with neuro-symbolic systems, which can be applied to a wide range of tasks, including multi-agent workflows, deterministic workflows, and even embedding models that can detect user intents and decide tool-use or LLM selection-based selection in vector space. This broader approach to agents has the potential to revolutionize the way we build AI systems, enabling them to tackle complex tasks that were previously thought to be beyond their capabilities. By thinking beyond ReAct and Tools, we can unlock a new era of innovation and progress in the field of artificial intelligence.\", 'new_suggestion': 'Article Paragraph Line: Agents are fundamental to the future of AI, but that doesn\\'t mean we should expect that future to come from agents in their most popular form today. While ReAct and Tool agents handle many simple use cases well, they are a narrow subset of what is possible with neuro-symbolic systems, which can be applied to a wide range of tasks, including multi-agent workflows, deterministic workflows, and even embedding models that can detect user intents and decide tool-use or LLM selection-based selection in vector space. This broader approach to agents has the potential to revolutionize the way we build AI systems, enabling them to tackle complex tasks that were previously thought to be beyond their capabilities. By thinking beyond ReAct and Tools, we can unlock a new era of innovation and progress in the field of artificial intelligence.\\n\\nThis paragraph should be placed after the section \"Not only LLMs and Tool Calls\" because it expands on the idea presented earlier about agents being more than just LLMs paired with tool calls. The previous section has already covered the basics of ReAct and Tool agents, and this new paragraph provides a broader context by mentioning multi-agent workflows, deterministic workflows, and embedding models as examples of alternative agent structures. By placing it after that section, we create a clear progression from introducing the concept of agents to exploring their potential applications and capabilities.', 'image_prompt': 'Here is a prompt to create an image based on the article:\\n\\n\"Create an illustration of a futuristic room with different sections representing various agents and their components. In the center, depict a large neural network (LLM) paired with a code editor, symbolizing the integration of neuro-symbolic systems. Surrounding the LLM-code pair, show different tools and executable code blocks, representing the \\'tools\\' used in the ReAct method. In the background, hint at future agent architectures, such as multi-agent workflows or embedding models, to convey the broader scope of agents. The image should evoke a sense of AI evolution and growth, with neural networks and code editors converging into powerful agents.\"\\n\\nImage style: Futuristic/High-tech'}\n"
     ]
    }
   ],
   "source": [
    "result = full_chain.invoke({\"article\": article})\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
