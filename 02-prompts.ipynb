{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c05d2acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use LangSmith\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://eu.api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"langhain-ollama-prompts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "391703e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Answer the user's query based on the context below.                 \n",
    "If you cannot answer the question using the\n",
    "provided information answer with \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e52f90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", prompt),\n",
    "    (\"user\", \"{query}\"),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3705a36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the same as previous but using MessagePromptTemplates\n",
    "from langchain_core.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(prompt),\n",
    "    HumanMessagePromptTemplate.from_template(\"{query}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0370f1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['context', 'query']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a1835d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nAnswer the user\\'s query based on the context below.                 \\nIf you cannot answer the question using the\\nprovided information answer with \"I don\\'t know\".\\n\\nContext: {context}\\n'), additional_kwargs={}),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5cb7dc",
   "metadata": {},
   "source": [
    "Invoke LLM with templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "806516ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "\n",
    "model_name = \"llama3.2\"\n",
    "\n",
    "#ititialize more determenistic model\n",
    "llm = ChatOllama(model=model_name, temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b1f5140",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = prompt_template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "000928d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"LangChain is a framework for developing applications powered by language models. It can be used for chatbots, Generative Question-Answering (GQA), summarization, and much more.\"\"\"\n",
    "query = \"What is LangChain used for?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc3fbfe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LangChain is a framework that can be used for various natural language processing (NLP) tasks, including:\\n\\n1. Chatbots\\n2. Generative Question-Answering (GQA)\\n3. Summarization\\n\\nThese are just a few examples of the many applications LangChain can be used for.', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-12-04T09:18:58.91637Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2705030417, 'load_duration': 1591120500, 'prompt_eval_count': 103, 'prompt_eval_duration': 154594583, 'eval_count': 63, 'eval_duration': 660613037, 'logprobs': None, 'model_name': 'llama3.2', 'model_provider': 'ollama'}, id='lc_run--581bc0ff-67b3-4ffc-bd53-e2e1b65fda11-0', usage_metadata={'input_tokens': 103, 'output_tokens': 63, 'total_tokens': 166})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.invoke({\"context\": context, \"query\": query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc335f9",
   "metadata": {},
   "source": [
    "Few Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ca88ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"ai\", \"{output}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "717b686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"input\": \"What is the capital of France?\",\n",
    "        \"output\": \"The capital of France is Paris.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Who wrote 'To Kill a Mockingbird'?\",\n",
    "        \"output\": \"'To Kill a Mockingbird' was written by Harper Lee.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5008bf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: What is the capital of France?\n",
      "AI: The capital of France is Paris.\n",
      "Human: Who wrote 'To Kill a Mockingbird'?\n",
      "AI: 'To Kill a Mockingbird' was written by Harper Lee.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    ")\n",
    "\n",
    "print(few_shot_prompt.format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fdebabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Overview of LangChain**\n",
      "========================\n",
      "\n",
      "LangChain is a framework that enables the development of applications powered by language models. It provides a set of tools and libraries to build various types of applications.\n",
      "\n",
      "### Key Use Cases\n",
      "\n",
      "*   **Chatbots**: LangChain can be used to build conversational interfaces, enabling users to interact with applications through natural language.\n",
      "*   **Generative Question-Answering (GQA)**: The framework allows developers to create systems that generate questions and answers based on a given prompt or context.\n",
      "*   **Summarization**: LangChain can be utilized for text summarization tasks, such as condensing long documents into concise summaries.\n",
      "\n",
      "### Other Applications\n",
      "\n",
      "*   **Content Generation**: LangChain can be used to generate content, such as articles, social media posts, or product descriptions.\n",
      "*   **Language Translation**: The framework provides tools for building language translation systems that can translate text from one language to another.\n",
      "*   **Text Classification**: LangChain enables developers to build systems that classify text into predefined categories.\n",
      "\n",
      "### Summary\n",
      "\n",
      "LangChain is a versatile framework that can be used to develop a wide range of applications powered by language models. Its key use cases include chatbots, GQA, summarization, content generation, language translation, and text classification.\n"
     ]
    }
   ],
   "source": [
    "new_system_prompt = \"\"\"\n",
    "Answer the user's query based on the context below.                 \n",
    "If you cannot answer the question using the\n",
    "provided information answer with \"I don't know\".\n",
    "\n",
    "Always answer in markdown format. When doing so please\n",
    "provide headers, short summaries, follow with bullet\n",
    "points, then conclude.\n",
    "\n",
    "Context: {context}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template.messages[0].prompt.template = new_system_prompt\n",
    "\n",
    "out = pipeline.invoke({\"context\": context, \"query\": query}).content\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fa38870",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"input\": \"Can you explain gravity?\",\n",
    "        \"output\": (\n",
    "            \"## Gravity\\n\\n\"\n",
    "            \"Gravity is one of the fundamental forces in the universe.\\n\\n\"\n",
    "            \"### Discovery\\n\\n\"\n",
    "            \"* Gravity was first discovered by Sir Isaac Newton in the late 17th century.\\n\"\n",
    "            \"* It was said that Newton theorized about gravity after seeing an apple fall from a tree.\\n\\n\"\n",
    "            \"### In General Relativity\\n\\n\"\n",
    "            \"* Gravity is described as the curvature of spacetime.\\n\"\n",
    "            \"* The more massive an object is, the more it curves spacetime.\\n\"\n",
    "            \"* This curvature is what causes objects to fall towards each other.\\n\\n\"\n",
    "            \"### Gravitons\\n\\n\"\n",
    "            \"* Gravitons are hypothetical particles that mediate the force of gravity.\\n\"\n",
    "            \"* They have not yet been detected.\\n\\n\"\n",
    "            \"**To conclude**, Gravity is a fascinating topic and has been studied extensively since the time of Newton.\\n\\n\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"What is the capital of France?\",\n",
    "        \"output\": (\n",
    "            \"## France\\n\\n\"\n",
    "            \"The capital of France is Paris.\\n\\n\"\n",
    "            \"### Origins\\n\\n\"\n",
    "            \"* The name Paris comes from the Latin word \\\"Parisini\\\" which referred to a Celtic people living in the area.\\n\"\n",
    "            \"* The Romans named the city Lutetia, which means \\\"the place where the river turns\\\".\\n\"\n",
    "            \"* The city was renamed Paris in the 3rd century BC by the Celtic-speaking Parisii tribe.\\n\\n\"\n",
    "            \"**To conclude**, Paris is highly regarded as one of the most beautiful cities in the world and is one of the world's greatest cultural and economic centres.\\n\\n\"\n",
    "        )\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dad4065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8317a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Human: Can you explain gravity?\n",
       "AI: ## Gravity\n",
       "\n",
       "Gravity is one of the fundamental forces in the universe.\n",
       "\n",
       "### Discovery\n",
       "\n",
       "* Gravity was first discovered by Sir Isaac Newton in the late 17th century.\n",
       "* It was said that Newton theorized about gravity after seeing an apple fall from a tree.\n",
       "\n",
       "### In General Relativity\n",
       "\n",
       "* Gravity is described as the curvature of spacetime.\n",
       "* The more massive an object is, the more it curves spacetime.\n",
       "* This curvature is what causes objects to fall towards each other.\n",
       "\n",
       "### Gravitons\n",
       "\n",
       "* Gravitons are hypothetical particles that mediate the force of gravity.\n",
       "* They have not yet been detected.\n",
       "\n",
       "**To conclude**, Gravity is a fascinating topic and has been studied extensively since the time of Newton.\n",
       "\n",
       "\n",
       "Human: What is the capital of France?\n",
       "AI: ## France\n",
       "\n",
       "The capital of France is Paris.\n",
       "\n",
       "### Origins\n",
       "\n",
       "* The name Paris comes from the Latin word \"Parisini\" which referred to a Celtic people living in the area.\n",
       "* The Romans named the city Lutetia, which means \"the place where the river turns\".\n",
       "* The city was renamed Paris in the 3rd century BC by the Celtic-speaking Parisii tribe.\n",
       "\n",
       "**To conclude**, Paris is highly regarded as one of the most beautiful cities in the world and is one of the world's greatest cultural and economic centres.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "out = few_shot_prompt.format()\n",
    "display(Markdown(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e542c464",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", new_system_prompt),\n",
    "    few_shot_prompt,\n",
    "    (\"user\", \"{query}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b034472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## LangChain\n",
       "\n",
       "LangChain is a framework for developing applications powered by language models.\n",
       "\n",
       "### Applications\n",
       "\n",
       "* **Chatbots**: LangChain can be used to build conversational interfaces that use natural language processing (NLP) and machine learning.\n",
       "* **Generative Question-Answering (GQA)**: LangChain enables the creation of AI systems that can answer questions based on their understanding of a given text or context.\n",
       "* **Summarization**: LangChain can be used to summarize long pieces of text into shorter, more digestible versions.\n",
       "\n",
       "### Key Features\n",
       "\n",
       "* **Modular Architecture**: LangChain's modular design allows developers to easily integrate different components and tools into their applications.\n",
       "* **Language Model Integration**: LangChain provides a simple way to integrate language models into applications, making it easy to build AI-powered interfaces.\n",
       "* **Extensive Library of Tools**: LangChain comes with an extensive library of tools and pre-built components that can be used to speed up development.\n",
       "\n",
       "**To conclude**, LangChain is a powerful framework for building AI-powered applications that use language models."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline = prompt_template | llm\n",
    "out = pipeline.invoke({\"context\": context, \"query\": query}).content\n",
    "display(Markdown(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34167f6b",
   "metadata": {},
   "source": [
    "Chain of Thought Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68beb4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test LLM without Chain of Thought prompting\n",
    "simple_prompt = \"\"\"\n",
    "Be a helpful assistant and answer the user's question.\n",
    "\n",
    "You MUST answer the question directly without any other\n",
    "text or explanation.\n",
    "\"\"\"\n",
    "\n",
    "simple_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", simple_prompt),\n",
    "    (\"user\", \"{query}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "299bc28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "query = (\n",
    "    \"James has 7 apples, he eats 4 and is given an additional 19 apples, \"\n",
    "    \"James gives 15 apples to Josh, and Josh gives James 2 apples, how \"\n",
    "    \"many apples does James have?\" \n",
    ")\n",
    "\n",
    "simple_pipeline = simple_prompt_template | llm\n",
    "simple_out = simple_pipeline.invoke({\"query\": query}).content\n",
    "print(simple_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa4efe2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To solve this problem, we need to break it down into smaller subproblems. Here are the steps:\n",
       "\n",
       "**Subproblem 1: Initial number of apples**\n",
       "James starts with 7 apples.\n",
       "\n",
       "**Subproblem 2: Apples eaten by James**\n",
       "James eats 4 apples, so he now has:\n",
       "7 - 4 = 3 apples\n",
       "\n",
       "**Subproblem 3: Additional apples given to James**\n",
       "James is given an additional 19 apples, so he now has:\n",
       "3 + 19 = 22 apples\n",
       "\n",
       "**Subproblem 4: Apples given by Josh to James**\n",
       "Josh gives James 2 apples, so James now has:\n",
       "22 + 2 = 24 apples\n",
       "\n",
       "**Subproblem 5: Apples given by James to Josh**\n",
       "James gives 15 apples to Josh, so he now has:\n",
       "24 - 15 = 9 apples\n",
       "\n",
       "Therefore, after all the transactions, James has **9 apples**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cot_system_prompt = \"\"\"\n",
    "Be a helpful assistant and answer the user's question.\n",
    "\n",
    "To answer the question, you must:\n",
    "\n",
    "- List systematically and in precise detail all\n",
    "  subproblems that need to be solved to answer the\n",
    "  question.\n",
    "- Solve each sub problem INDIVIDUALLY and in sequence.\n",
    "- Finally, use everything you have worked through to\n",
    "  provide the final answer.\n",
    "\n",
    "Context: {context}\n",
    "\"\"\"\n",
    "\n",
    "cot_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", cot_system_prompt),\n",
    "    (\"user\", \"{query}\"),\n",
    "])\n",
    "\n",
    "cot_pipeline = cot_prompt_template | llm\n",
    "cot_out = cot_pipeline.invoke({\"context\": context, \"query\": query}).content\n",
    "display(Markdown(cot_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27043b83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
